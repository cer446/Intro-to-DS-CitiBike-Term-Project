{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding features with coefficients set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import project_env\n",
    "from imp import reload\n",
    "import math\n",
    "import os\n",
    "import run_logreg\n",
    "import project_env\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "reload(project_env)\n",
    "reload(run_logreg)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `project_env` package**\n",
    "\n",
    "I wrote this python package so loading and working with data is quicker and easier. There are several convenience methods:\n",
    "* `load_split_bucket(station_id)` - Load data for a bike station that's already pre-split into train, dev and test. Includes doing data cleaning and thresholding. The output is a dictionary:\n",
    "```\n",
    "  {\n",
    "    'train': (DataFrame, Series),\n",
    "    'dev': (DataFrame, Series),\n",
    "    'test': (DataFrame, Series)\n",
    "  }\n",
    "```\n",
    "  Each `(DataFrame, Series)` tuple is the feature values and target variables, respectively.\n",
    "* `merge_training(split, df)` - Given two outputs of `load()`, append the training set of the second argument to the training set of the first. This is useful when trying to load data from multiple stations, but testing on one station only.\n",
    "* `binarize(data, target)` - Given output of `load()` and either 1 or -1, binarize the target variable to 0 or 1. Whatever class is in the second argument will become '1' in the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `run_logreg` package**\n",
    "\n",
    "We wrote this python package so running many logistic regression models with different parameters is cleaner and easier. Here are the methods included:\n",
    "\n",
    "* `do_logreg` - Takes the result of split_data and performs a logistic regression given the input parameters. It takes a parameters called \"squares\" that will perform some basic feature engineering by squaring some of the variables, a penalty function (l1 or l2, defaults to l2), and a c parameter (defaults to 100,000).\n",
    "\n",
    "* `distance` - Calculates the distance betweent two stations, based on the distance formula\n",
    "\n",
    "* `closest_stations` - Identifies the stations closest to the input station, using the `distance` function\n",
    "\n",
    "* `add_closest_stations` - Takes split_data for one station and its station_id, splits, merges the closest stations' data and binarizes all\n",
    "\n",
    "* `format_plot` - Formats the plot according to the desired target_recall and whether this is a plot of empty or full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Logistic_Regression_Specs():\n",
    "    def __init__(self, split_data, stationid, target, empty=True, squares=False, num_append=0, C=1e5, penalty='l2'):\n",
    "        self.stationid = stationid\n",
    "        self.target = target\n",
    "        self.split_data = split_data\n",
    "        self.empty = empty\n",
    "        self.squares = squares\n",
    "        self.num_append = num_append\n",
    "        self.penalty = penalty\n",
    "        self.C = C\n",
    "\n",
    "def construct_key(spec):\n",
    "    key = ''\n",
    "    if spec.target != 'y_60m':\n",
    "        key = key + spec.target + ' '\n",
    "    if spec.squares == True:\n",
    "        key = key + 'squares; '\n",
    "    if spec.num_append > 0:\n",
    "        key = key + 'append: ' + str(spec.num_append) + '; '\n",
    "    key = key + 'penalty: ' + spec.penalty + '; '\n",
    "    key = key + 'c: ' + str(spec.C) + '; '\n",
    "    return key\n",
    "\n",
    "def run_models(list_of_specs):\n",
    "    '''Creates a dictionary of models based on list of specs objects'''\n",
    "    \n",
    "    logregs = {}\n",
    "    scalers = {}\n",
    "    predictions = {}\n",
    "    specs = {}\n",
    "    \n",
    "    for spec in list_of_specs:\n",
    "        logregs[construct_key(spec)], scalers[construct_key(spec)], predictions[construct_key(spec)] = run_logreg.do_logreg(spec, plot = False) \n",
    "        specs[(construct_key(spec))] = spec\n",
    "    return logregs, scalers, predictions, specs\n",
    "\n",
    "def pr_curve(predictions, true_value, target_recall=0.95):\n",
    "    curve = precision_recall_curve(true_value, predictions)\n",
    "    precision, recall, thresholds = curve\n",
    "    mp, mr, mt = project_env.max_precision_for_recall(curve, target_recall=target_recall)\n",
    "    return mp, mr, mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading\n"
     ]
    }
   ],
   "source": [
    "# test loading data\n",
    "data = project_env.load_split_bucket(519, target='y_60m', log=False)\n",
    "print('done loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.798553719008\n",
      "[[659 142]\n",
      " [ 53 114]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.785123966942\n",
      "[[632 169]\n",
      " [ 39 128]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.780991735537\n",
      "[[626 175]\n",
      " [ 37 130]]\n"
     ]
    }
   ],
   "source": [
    "# best prediction: ['y_60m', False, 0, 10, 'l1']\n",
    "\n",
    "data = project_env.load_split_bucket(519, target='y_60m', log=False)\n",
    "\n",
    "spec001 = Logistic_Regression_Specs(data, stationid=519, target='y_60m', empty=True, squares=False, num_append=0, C=0.1, penalty='l1')\n",
    "spec010 = Logistic_Regression_Specs(data, stationid=519, target='y_60m', empty=True, squares=False, num_append=0, C=1, penalty='l1')\n",
    "spec100 = Logistic_Regression_Specs(data, stationid=519, target='y_60m', empty=True, squares=False, num_append=0, C=10, penalty='l1')\n",
    "\n",
    "logregs_e_001, scalers_e, predictions_e = run_logreg.do_logreg(spec001, plot=False, merge_train_dev=True)\n",
    "logregs_e_010, scalers_e, predictions_e = run_logreg.do_logreg(spec010, plot=False, merge_train_dev=True)\n",
    "logregs_e_100, scalers_e, predictions_e = run_logreg.do_logreg(spec100, plot=False, merge_train_dev=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparentTemperature</th>\n",
       "      <td>-0.381</td>\n",
       "      <td>-1.210</td>\n",
       "      <td>-1.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudCover</th>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewPoint</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.947</td>\n",
       "      <td>3.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.745</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-1.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nearestStormDistance</th>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ozone</th>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipIntensity</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipProbability</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-1.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visibility</th>\n",
       "      <td>0.253</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windBearing</th>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windSpeed</th>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>-0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bikes_available_scaled</th>\n",
       "      <td>-2.038</td>\n",
       "      <td>-2.178</td>\n",
       "      <td>-2.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bikes_disabled_scaled</th>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_docks_available_scaled</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour_of_day</th>\n",
       "      <td>0.427</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic_0_speed_scrub</th>\n",
       "      <td>0.246</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic_1_speed_scrub</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic_2_speed_scrub</th>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0      1       2\n",
       "C                           0.100  1.000  10.000\n",
       "apparentTemperature        -0.381 -1.210  -1.247\n",
       "cloudCover                 -0.190 -0.199  -0.194\n",
       "dewPoint                    0.000  1.947   3.316\n",
       "humidity                    0.745 -0.331  -1.142\n",
       "nearestStormDistance       -0.192 -0.232  -0.242\n",
       "ozone                      -0.074 -0.133  -0.147\n",
       "precipIntensity             0.079  0.144   0.156\n",
       "precipProbability           0.000 -0.031  -0.047\n",
       "pressure                    0.109  0.152   0.159\n",
       "temperature                 0.000 -0.816  -1.906\n",
       "visibility                  0.253  0.247   0.203\n",
       "windBearing                -0.114 -0.113  -0.113\n",
       "windSpeed                  -0.432 -0.508  -0.523\n",
       "num_bikes_available_scaled -2.038 -2.178  -2.832\n",
       "num_bikes_disabled_scaled  -0.066 -0.125  -0.218\n",
       "num_docks_available_scaled  0.056  0.000  -0.667\n",
       "day_of_week                -0.073 -0.103  -0.107\n",
       "hour_of_day                 0.427  0.487   0.488\n",
       "is_weekend                 -0.379 -0.408  -0.412\n",
       "traffic_0_speed_scrub       0.246  0.269   0.284\n",
       "traffic_1_speed_scrub       0.215  0.235   0.229\n",
       "traffic_2_speed_scrub      -0.287 -0.332  -0.343"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients\n",
    "\n",
    "data_empty = project_env.binarize(data, -1)\n",
    "#print(logregs_e.coef_.ravel())\n",
    "#print(data_empty['train'][0].columns.ravel())\n",
    "\n",
    "#coef_rows = logregs_e.coef_.ravel()\n",
    "#coef_rows.append(logregs_e.coef_.ravel())\n",
    "#coef_df = pd.DataFrame(coef_rows, columns=data_empty['train'][0].columns.ravel())\n",
    "col_names = data_empty['train'][0].columns.ravel()\n",
    "col_names = np.append(['C'], col_names)\n",
    "\n",
    "coef_df = pd.DataFrame(columns=col_names)\n",
    "coef_df = coef_df.append(pd.Series(np.append([0.1], logregs_e_001.coef_.ravel()), index=col_names), ignore_index=True)\n",
    "coef_df = coef_df.append(pd.Series(np.append([1], logregs_e_010.coef_.ravel()), index=col_names), ignore_index=True)\n",
    "coef_df = coef_df.append(pd.Series(np.append([10], logregs_e_100.coef_.ravel()), index=col_names), ignore_index=True)\n",
    "\n",
    "coef_df.transpose().round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the value of C, there are few or no features with coefficient of 0. Smaller values specify stronger regularization. At C=10, no features are set to 0 and you need to reduce C to start seeing 0s.\n",
    "\n",
    "Although most features are fairly stable regardless of C, dew point changes dramatically. It's 0 at C=0.1, but is the highest for C=10. Also of note is humidity, which goes from one of the most positive to one of the most negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
