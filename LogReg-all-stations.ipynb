{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import project_env\n",
    "from imp import reload\n",
    "import math\n",
    "import os\n",
    "import run_logreg\n",
    "import project_env\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "#reload(project_env)\n",
    "#reload(run_logreg)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `project_env` package**\n",
    "\n",
    "I wrote this python package so loading and working with data is quicker and easier. There are several convenience methods:\n",
    "* `load_split_bucket(station_id)` - Load data for a bike station that's already pre-split into train, dev and test. Includes doing data cleaning and thresholding. The output is a dictionary:\n",
    "```\n",
    "  {\n",
    "    'train': (DataFrame, Series),\n",
    "    'dev': (DataFrame, Series),\n",
    "    'test': (DataFrame, Series)\n",
    "  }\n",
    "```\n",
    "  Each `(DataFrame, Series)` tuple is the feature values and target variables, respectively.\n",
    "* `merge_training(split, df)` - Given two outputs of `load()`, append the training set of the second argument to the training set of the first. This is useful when trying to load data from multiple stations, but testing on one station only.\n",
    "* `binarize(data, target)` - Given output of `load()` and either 1 or -1, binarize the target variable to 0 or 1. Whatever class is in the second argument will become '1' in the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `run_logreg` package**\n",
    "\n",
    "We wrote this python package so running many logistic regression models with different parameters is cleaner and easier. Here are the methods included:\n",
    "\n",
    "* `do_logreg` - Takes the result of split_data and performs a logistic regression given the input parameters. It takes a parameters called \"squares\" that will perform some basic feature engineering by squaring some of the variables, a penalty function (l1 or l2, defaults to l2), and a c parameter (defaults to 100,000).\n",
    "\n",
    "* `distance` - Calculates the distance betweent two stations, based on the distance formula\n",
    "\n",
    "* `closest_stations` - Identifies the stations closest to the input station, using the `distance` function\n",
    "\n",
    "* `add_closest_stations` - Takes split_data for one station and its station_id, splits, merges the closest stations' data and binarizes all\n",
    "\n",
    "* `format_plot` - Formats the plot according to the desired target_recall and whether this is a plot of empty or full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Logistic_Regression_Specs():\n",
    "    def __init__(self, split_data, stationid, target, empty=True, squares=False, num_append=0, C=1e5, penalty='l2'):\n",
    "        self.stationid = stationid\n",
    "        self.target = target\n",
    "        self.split_data = split_data\n",
    "        self.empty = empty\n",
    "        self.squares = squares\n",
    "        self.num_append = num_append\n",
    "        self.penalty = penalty\n",
    "        self.C = C\n",
    "\n",
    "def construct_key(spec):\n",
    "    key = ''\n",
    "    if spec.target != 'y_60m':\n",
    "        key = key + spec.target + ' '\n",
    "    if spec.squares == True:\n",
    "        key = key + 'squares; '\n",
    "    if spec.num_append > 0:\n",
    "        key = key + 'append: ' + str(spec.num_append) + '; '\n",
    "    key = key + 'penalty: ' + spec.penalty + '; '\n",
    "    key = key + 'c: ' + str(spec.C) + '; '\n",
    "    return key\n",
    "\n",
    "def run_models(list_of_specs):\n",
    "    '''Creates a dictionary of models based on list of specs objects'''\n",
    "    \n",
    "    logregs = {}\n",
    "    scalers = {}\n",
    "    predictions = {}\n",
    "    specs = {}\n",
    "    \n",
    "    for spec in list_of_specs:\n",
    "        logregs[construct_key(spec)], scalers[construct_key(spec)], predictions[construct_key(spec)] = run_logreg.do_logreg(spec, plot = False) \n",
    "        specs[(construct_key(spec))] = spec\n",
    "    return logregs, scalers, predictions, specs\n",
    "\n",
    "def pr_curve(predictions, true_value, target_recall=0.95):\n",
    "    curve = precision_recall_curve(true_value, predictions)\n",
    "    precision, recall, thresholds = curve\n",
    "    mp, mr, mt = project_env.max_precision_for_recall(curve, target_recall=target_recall)\n",
    "    return mp, mr, mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading\n",
      "(4236, 22)\n",
      "(4236,)\n",
      "(968, 22)\n",
      "(968, 22)\n",
      "(5204, 22)\n",
      "(5204,)\n"
     ]
    }
   ],
   "source": [
    "# test loading data\n",
    "data = project_env.load_split_bucket(519, target='y_60m', log=False)\n",
    "print('done loading')\n",
    "\n",
    "\n",
    "# merge test\n",
    "train_X, train_y = data['train']\n",
    "dev_X, dev_y = data['dev']\n",
    "test_X, test_y = data['test']\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(dev_X.shape)\n",
    "print(test_X.shape)\n",
    "\n",
    "merged_X = pd.concat([train_X, dev_X])\n",
    "merged_y = pd.concat([train_y, dev_y])\n",
    "print(merged_X.shape)\n",
    "print(merged_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set X shape: (4236, 22)\n",
      "Trained on train set of 4236 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.813016528926\n",
      "[[448 137]\n",
      " [ 44 339]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.785123966942\n",
      "[[632 169]\n",
      " [ 39 128]]\n",
      "[-1.20952231 -0.19910611  1.95139902 -0.33429963 -0.23217302 -0.13263556\n",
      "  0.14399405 -0.03146774  0.15151968 -0.8208618   0.24692    -0.11329219\n",
      " -0.50806772 -2.17808851 -0.12506055  0.         -0.10327851  0.48715597\n",
      " -0.40761112  0.26897746  0.23543154 -0.33159617]\n",
      "['apparentTemperature' 'cloudCover' 'dewPoint' 'humidity'\n",
      " 'nearestStormDistance' 'ozone' 'precipIntensity' 'precipProbability'\n",
      " 'pressure' 'temperature' 'visibility' 'windBearing' 'windSpeed'\n",
      " 'num_bikes_available_scaled' 'num_bikes_disabled_scaled'\n",
      " 'num_docks_available_scaled' 'day_of_week' 'hour_of_day' 'is_weekend'\n",
      " 'traffic_0_speed_scrub' 'traffic_1_speed_scrub' 'traffic_2_speed_scrub']\n"
     ]
    }
   ],
   "source": [
    "# best prediction: ['y_60m', False, 0, 10, 'l1']\n",
    "\n",
    "data = project_env.load_split_bucket(519, target='y_60m', log=False)\n",
    "spec = Logistic_Regression_Specs(data, stationid=519, target='y_60m', empty=True, squares=False, num_append=0, C=1.0, penalty='l1')\n",
    "\n",
    "logregs_e, scalers_e, predictions_e = run_logreg.do_logreg(spec, plot=False)\n",
    "\n",
    "logregs_e, scalers_e, predictions_e = run_logreg.do_logreg(spec, plot=False, merge_train_dev=True)\n",
    "\n",
    "data_empty = project_env.binarize(data, -1)\n",
    "#gold_labels = data_empty['dev'][1]\n",
    "\n",
    "#mp, mr, mt = pr_curve(predictions_e, gold_labels, target_recall=0.95)\n",
    "#print(mp, mr, mt)\n",
    "\n",
    "print(logregs_e.coef_.ravel())\n",
    "print(data_empty['train'][0].columns.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_30m', False, 0, 0.01, 'l1']\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.890927624873\n",
      "[[744  71]\n",
      " [ 36 130]]\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.900101936799\n",
      "[[883   0]\n",
      " [ 98   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/id460/miniconda3/lib/python3.5/site-packages/pandas/core/indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_30m', False, 0, 0.1, 'l1']\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.870540265036\n",
      "[[728  87]\n",
      " [ 40 126]]\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.90621814475\n",
      "[[872  11]\n",
      " [ 81  17]]\n",
      "['y_30m', False, 0, 1, 'l1']\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.86748216106\n",
      "[[711 104]\n",
      " [ 26 140]]\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.900101936799\n",
      "[[873  10]\n",
      " [ 88  10]]\n",
      "['y_30m', False, 0, 10, 'l1']\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.862385321101\n",
      "[[705 110]\n",
      " [ 25 141]]\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.904179408767\n",
      "[[873  10]\n",
      " [ 84  14]]\n",
      "['y_30m', False, 0, 100, 'l1']\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.863404689093\n",
      "[[705 110]\n",
      " [ 24 142]]\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.905198776758\n",
      "[[873  10]\n",
      " [ 83  15]]\n",
      "['y_30m', False, 0, 1000, 'l1']\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.863404689093\n",
      "[[705 110]\n",
      " [ 24 142]]\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.905198776758\n",
      "[[873  10]\n",
      " [ 83  15]]\n",
      "['y_30m', False, 0, 10000, 'l1']\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.863404689093\n",
      "[[705 110]\n",
      " [ 24 142]]\n",
      "Training set X shape: (5286, 22)\n",
      "Trained on train set of 5286 examples\n",
      "Evaluating on dev set of 981 examples\n",
      "Accuracy: 0.905198776758\n",
      "[[873  10]\n",
      " [ 83  15]]\n",
      "['y_60m', False, 0, 0.01, 'l1']\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.855371900826\n",
      "[[720  81]\n",
      " [ 59 108]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.89979338843\n",
      "[[871   0]\n",
      " [ 97   0]]\n",
      "['y_60m', False, 0, 0.1, 'l1']\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.798553719008\n",
      "[[659 142]\n",
      " [ 53 114]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.898760330579\n",
      "[[870   1]\n",
      " [ 97   0]]\n",
      "['y_60m', False, 0, 1, 'l1']\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.785123966942\n",
      "[[632 169]\n",
      " [ 39 128]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.898760330579\n",
      "[[870   1]\n",
      " [ 97   0]]\n",
      "['y_60m', False, 0, 10, 'l1']\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.780991735537\n",
      "[[626 175]\n",
      " [ 37 130]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.898760330579\n",
      "[[870   1]\n",
      " [ 97   0]]\n",
      "['y_60m', False, 0, 100, 'l1']\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.780991735537\n",
      "[[626 175]\n",
      " [ 37 130]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.898760330579\n",
      "[[870   1]\n",
      " [ 97   0]]\n",
      "['y_60m', False, 0, 1000, 'l1']\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.780991735537\n",
      "[[626 175]\n",
      " [ 37 130]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.898760330579\n",
      "[[870   1]\n",
      " [ 97   0]]\n",
      "['y_60m', False, 0, 10000, 'l1']\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.780991735537\n",
      "[[626 175]\n",
      " [ 37 130]]\n",
      "Training set X shape: (5204, 22)\n",
      "Trained on train set of 5204 examples\n",
      "Evaluating on dev set of 968 examples\n",
      "Accuracy: 0.898760330579\n",
      "[[870   1]\n",
      " [ 97   0]]\n"
     ]
    }
   ],
   "source": [
    "#target_vars = ['y_10m','y_15m','y_30m','y_45m','y_60m','y_90m','y_120m']\n",
    "target_vars = ['y_30m', 'y_60m']\n",
    "c_list = [.01, .1, 1, 10, 100, 1000, 10000]\n",
    "#c_list = [.01, 1, 100]\n",
    "penalties = ['l1']\n",
    "#sq_list = [True, False]\n",
    "sq_list = [False]\n",
    "#num_append_list = [0,1,10]\n",
    "num_append_list = [0]\n",
    "target_list = {}\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "#Returns a dictionary within a dictionary.  Outer dictionary is keyed on target var. inner dictionary keyed on a \n",
    "# \"model number\" and contains the specs of the model as well as a list of the [mp,mr,mt]\n",
    "# You can probably used this to find the max MR for each target variable\n",
    "for target in target_vars:\n",
    "    data = project_env.load_split_bucket(519, target=target, log=False)\n",
    "    data_empty = project_env.binarize(data, -1)\n",
    "    # gold_labels = data_empty['dev'][1]\n",
    "    gold_labels_e = data_empty['test'][1]\n",
    "    data_full = project_env.binarize(data, 1)\n",
    "    gold_labels_f = data_full['test'][1]\n",
    "    \n",
    "    models = {}\n",
    "    model_id=0\n",
    "    rows = int(len(sq_list))*int(len(num_append_list))*int(len(c_list))*int(len(penalties))*2\n",
    "    \n",
    "    columns=['specs', 'mp', 'mr', 'mt']\n",
    "    df_dict[target] = pd.DataFrame(data=np.zeros((rows,len(columns))), columns=columns) \n",
    "    \n",
    "    for squares in sq_list:\n",
    "        for num_append in num_append_list:\n",
    "            for c in c_list:\n",
    "                for penalty in penalties:\n",
    "\n",
    "                    print([target, squares, num_append, c, penalty])\n",
    "                    \n",
    "                    spec_e = Logistic_Regression_Specs(data, 519, target, empty=True, squares=squares, num_append=num_append, C=c, penalty=penalty)\n",
    "                    spec_f = Logistic_Regression_Specs(data, 519, target, empty=False, squares=squares, num_append=num_append, C=c, penalty=penalty)\n",
    "                    \n",
    "                    #logregs_e, scalers_e, predictions_e = run_logreg.do_logreg(spec, plot=False)\n",
    "                    logregs_e, scalers_e, predictions_e = run_logreg.do_logreg(spec_e, plot=False, merge_train_dev=True)\n",
    "                    logregs_f, scalers_f, predictions_f = run_logreg.do_logreg(spec_f, plot=False, merge_train_dev=True)\n",
    "                    #print(predictions_e)\n",
    "                    \n",
    "                    mp, mr, mt = pr_curve(predictions_e, gold_labels_e, target_recall=0.95)\n",
    "                    df_dict[target]['specs'].loc[model_id] = ['empty', target, squares, num_append, c, penalty]\n",
    "                    df_dict[target]['mp'].loc[model_id] = mp\n",
    "                    df_dict[target]['mr'].loc[model_id] = mr\n",
    "                    df_dict[target]['mt'].loc[model_id] = mt\n",
    "                    #model_specs = [target,squares,num_append,c,penalty]\n",
    "                    #models.setdefault(model_id,[]).append([model_specs,mp,mr,mt])\n",
    "                    model_id = model_id + 1\n",
    "                    \n",
    "                    mp, mr, mt = pr_curve(predictions_f, gold_labels_f, target_recall=0.95)\n",
    "                    df_dict[target]['specs'].loc[model_id] = ['full', target, squares, num_append, c, penalty]\n",
    "                    df_dict[target]['mp'].loc[model_id] = mp\n",
    "                    df_dict[target]['mr'].loc[model_id] = mr\n",
    "                    df_dict[target]['mt'].loc[model_id] = mt\n",
    "                    model_id = model_id + 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for target in target_vars:\n",
    "    df_dict[target].to_csv(target + \".merged_train_dev.csv\")\n",
    "\n",
    "# [target,squares,num_append,c,penalty]\n",
    "# max_pre, max_rec, max_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### optimal Cs based on max prediction:\n",
    "\n",
    " - y_30m merged_train_dev empty - 0.01\n",
    " - y_30m merged_train_dev full - 0.1\n",
    " - y_60m merged_train_dev empty - 100\n",
    " - y_60m merged_train_dev full - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import string\n",
    "\n",
    "data_path = 'per_station_train'\n",
    "station_files = sorted([f for f in listdir(data_path) if isfile(join(data_path, f))])\n",
    "station_files = list(filter(lambda f: 'swp' not in f, station_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Training set X shape: (3835, 22)\n",
      "Trained on train set of 3835 examples\n",
      "Evaluating on dev set of 545 examples\n",
      "Accuracy: 0.985321100917\n",
      "[[537   0]\n",
      " [  8   0]]\n",
      "Training set X shape: (3835, 22)\n",
      "Trained on train set of 3835 examples\n",
      "Evaluating on dev set of 545 examples\n",
      "Accuracy: 0.733944954128\n",
      "[[329  91]\n",
      " [ 54  71]]\n",
      "Training set X shape: (3835, 22)\n",
      "Trained on train set of 3835 examples\n",
      "Evaluating on dev set of 545 examples\n",
      "Accuracy: 0.985321100917\n",
      "[[537   0]\n",
      " [  8   0]]\n",
      "Training set X shape: (3835, 22)\n",
      "Trained on train set of 3835 examples\n",
      "Evaluating on dev set of 545 examples\n",
      "Accuracy: 0.733944954128\n",
      "[[329  91]\n",
      " [ 54  71]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [548, 545]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f02df293d936>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlogregs_60_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalers_30_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_30_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_logreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_logreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_30_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_train_dev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpr_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_30_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_labels_30_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_recall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstation_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'empty'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-aec49792f201>\u001b[0m in \u001b[0;36mpr_curve\u001b[0;34m(predictions, true_value, target_recall)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpr_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_recall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mcurve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_precision_for_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_recall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_recall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/id460/miniconda3/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    411\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/id460/miniconda3/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mDecreasing\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \"\"\"\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/id460/miniconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [548, 545]"
     ]
    }
   ],
   "source": [
    "model_id = 0\n",
    "\n",
    "for s in station_files:\n",
    "    station_id = s.replace('.csv', '')\n",
    "    print(station_id)\n",
    "\n",
    "    data = project_env.load_split_bucket(station_id, target='y_30m', log=False)\n",
    "    data_empty = project_env.binarize(data, -1)\n",
    "    gold_labels_30_e = data_empty['test'][1]\n",
    "    data_full = project_env.binarize(data, 1)\n",
    "    gold_labels_30_f = data_full['test'][1]\n",
    "    \n",
    "    data = project_env.load_split_bucket(station_id, target='y_60m', log=False)\n",
    "    data_empty = project_env.binarize(data, -1)\n",
    "    gold_labels_60_e = data_empty['test'][1]\n",
    "    data_full = project_env.binarize(data, 1)\n",
    "    gold_labels_60_f = data_full['test'][1]\n",
    "    \n",
    "    spec_30_e = Logistic_Regression_Specs(data, station_id, 'y_30m', empty=True, squares=False, num_append=0, C=0.01, penalty='l1')\n",
    "    spec_30_f = Logistic_Regression_Specs(data, station_id, 'y_30m', empty=False, squares=False, num_append=0, C=0.1, penalty='l1')\n",
    "    spec_60_e = Logistic_Regression_Specs(data, station_id, 'y_60m', empty=True, squares=False, num_append=0, C=100, penalty='l1')\n",
    "    spec_60_f = Logistic_Regression_Specs(data, station_id, 'y_60m', empty=False, squares=False, num_append=0, C=0.1, penalty='l1')\n",
    "                    \n",
    "    logregs_30_e, scalers_30_e, predictions_30_e = run_logreg.do_logreg(spec_30_e, plot=False, merge_train_dev=True)\n",
    "    logregs_30_f, scalers_30_f, predictions_30_f = run_logreg.do_logreg(spec_30_f, plot=False, merge_train_dev=True)\n",
    "    logregs_60_e, scalers_30_e, predictions_30_e = run_logreg.do_logreg(spec_30_e, plot=False, merge_train_dev=True)\n",
    "    logregs_60_f, scalers_30_f, predictions_30_f = run_logreg.do_logreg(spec_30_f, plot=False, merge_train_dev=True)\n",
    "\n",
    "    mp, mr, mt = pr_curve(predictions_30_e, gold_labels_30_e, target_recall=0.95)\n",
    "    df_dict[target]['station_id'].loc[model_id] = station_id\n",
    "    df_dict[target]['status'].loc[model_id] = 'empty'\n",
    "    df_dict[target]['target'].loc[model_id] = 'y_30m'\n",
    "    df_dict[target]['mp'].loc[model_id] = mp\n",
    "    df_dict[target]['mr'].loc[model_id] = mr\n",
    "    df_dict[target]['mt'].loc[model_id] = mt\n",
    "    model_id = model_id + 1\n",
    "\n",
    "    mp, mr, mt = pr_curve(predictions_30_f, gold_labels_30_f, target_recall=0.95)\n",
    "    df_dict[target]['station_id'].loc[model_id] = station_id\n",
    "    df_dict[target]['status'].loc[model_id] = 'full'\n",
    "    df_dict[target]['target'].loc[model_id] = 'y_30m'\n",
    "    df_dict[target]['mp'].loc[model_id] = mp\n",
    "    df_dict[target]['mr'].loc[model_id] = mr\n",
    "    df_dict[target]['mt'].loc[model_id] = mt\n",
    "    model_id = model_id + 1\n",
    "\n",
    "    mp, mr, mt = pr_curve(predictions_60_e, gold_labels_60_e, target_recall=0.95)\n",
    "    df_dict[target]['station_id'].loc[model_id] = station_id\n",
    "    df_dict[target]['status'].loc[model_id] = 'empty'\n",
    "    df_dict[target]['target'].loc[model_id] = 'y_60m'\n",
    "    df_dict[target]['mp'].loc[model_id] = mp\n",
    "    df_dict[target]['mr'].loc[model_id] = mr\n",
    "    df_dict[target]['mt'].loc[model_id] = mt\n",
    "    model_id = model_id + 1\n",
    "\n",
    "    mp, mr, mt = pr_curve(predictions_60_f, gold_labels_60_f, target_recall=0.95)\n",
    "    df_dict[target]['station_id'].loc[model_id] = station_id\n",
    "    df_dict[target]['status'].loc[model_id] = 'full'\n",
    "    df_dict[target]['target'].loc[model_id] = 'y_60m'\n",
    "    df_dict[target]['mp'].loc[model_id] = mp\n",
    "    df_dict[target]['mr'].loc[model_id] = mr\n",
    "    df_dict[target]['mt'].loc[model_id] = mt\n",
    "    model_id = model_id + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
